# **Lora под задачу на русском языке**

# **Предисловие**

Я старался максимально расписывать код, так что его запустить сможет буквально каждый. 
В ноутбуках очень много хэштэгов с пояснениями. Тетрадки собраны из многих моих черновиков, 
поэтому они могут показаться длинными. Возможно код не идеален, но он работает, чему я безусловно рад.

# **Личный мотив**
Для меня было интересно опробовать этот инструмент, поэтому постарался сделать его хотя бы не скучным,
чтобы во время написания кода, мне не хотелось плакать (хотелось) 

# **Информация по файлам**

***output.jsonl*** - размеченный датасет на котором модель доолучалась (размер 8641)

***data_small.jsonl*** - это датасет output.jsonl, но уменьшенный в 20 раз, использовался 
в песочнице, чтобы не тратить все свои ресурсы на Google Colab 

**LORA_END-28
**QVikhr-3-1.7B.ipynb**



